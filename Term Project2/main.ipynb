{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import natsort\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as copy\n",
    "import math\n",
    "import os\n",
    "import functions as ftn\n",
    "import Equirec2Perspec as E2P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOV = 110 # degree\n",
    "height = 640\n",
    "width = 640\n",
    "K = np.array([[2.240664122271071506e+02, 0.000000000000000000e+00, 3.200000000000000000e+02],\n",
    "            [0.000000000000000000e+00, 2.240664122271071506e+02, 3.200000000000000000e+02],\n",
    "            [0.000000000000000000e+00, 0.000000000000000000e+00, 1.000000000000000000e+00]])\n",
    "\n",
    "p = K[0,0]\n",
    "q = K[1,1]\n",
    "r = K[0,2]\n",
    "s = K[1,2]\n",
    "\n",
    "K_inv = np.linalg.inv(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LOAD IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000_ref.png', '00000_tar.png', '00001_ref.png', '00001_tar.png', '00002_ref.png', '00002_tar.png', '00003_ref.png', '00003_tar.png', '00004_ref.png', '00004_tar.png', '00005_ref.png', '00005_tar.png', '00006_ref.png', '00006_tar.png', '00007_ref.png', '00007_tar.png', '00008_ref.png', '00008_tar.png', '00009_ref.png', '00009_tar.png', '00010_ref.png', '00010_tar.png', '00011_ref.png', '00011_tar.png', '00012_ref.png', '00012_tar.png', '00013_ref.png', '00013_tar.png', '00014_ref.png', '00014_tar.png', '00015_ref.png', '00015_tar.png', '00016_ref.png', '00016_tar.png', '00017_ref.png', '00017_tar.png', '00018_ref.png', '00018_tar.png', '00019_ref.png', '00019_tar.png', '00020_ref.png', '00020_tar.png']\n"
     ]
    }
   ],
   "source": [
    "# recall color and gray images and mask\n",
    "\n",
    "path = './StereoImages/'\n",
    "order_list = os.listdir(path)\n",
    "after_order_list = natsort.natsorted(order_list)\n",
    "print(after_order_list)\n",
    "# left and right color images \n",
    "colors_left_list = []\n",
    "colors_right_list = []\n",
    "\n",
    "# left and right gray images\n",
    "grays_left_list = []\n",
    "grays_right_list = []\n",
    "\n",
    "for root, directions, files in os.walk(path):\n",
    "    \n",
    "    for file in after_order_list:\n",
    "        img = cv.imread(os.path.join(root, file))\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if 'ref.png' in file:  \n",
    "            colors_left_list.append(img)\n",
    "            grays_left_list.append(gray)\n",
    "        \n",
    "        if 'tar.png' in file:\n",
    "            colors_right_list.append(img)\n",
    "            grays_right_list.append(gray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. FEATURE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_key_pts_list = [] # raw key point list for each left image\n",
    "descriptors_list = [] # descriptor list for each left image\n",
    "\n",
    "#detector = cv.BRISK_create()\n",
    "detector = cv.ORB_create()\n",
    "for i in range(21):\n",
    "    \n",
    "    raw_key_pts, descriptors = detector.detectAndCompute(grays_left_list[i], None)\n",
    "    raw_key_pts = np.float32([key_pt.pt for key_pt in raw_key_pts])\n",
    "    raw_key_pts_list.append(raw_key_pts)\n",
    "    descriptors_list.append(descriptors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. FIND DIFFERENCE ANGLE BETWEEN A PAIR OF IMAGES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359.92795\n"
     ]
    }
   ],
   "source": [
    "rot_angle_list = []\n",
    "sum = 0\n",
    "for i in range(20):\n",
    "    # a. find right features\n",
    "    key_pts1, key_pts2, matches = ftn.findRightFeatures(raw_key_pts_list[i], raw_key_pts_list[i+1], descriptors_list[i], descriptors_list[i+1])\n",
    "    \n",
    "    #print('%d, %d' % (len(key_pts1), len(key_pts2)))\n",
    "    key_pts1 = ftn.homoPixel2Camera(key_pts1, K_inv)\n",
    "    key_pts2 = ftn.homoPixel2Camera(key_pts2, K_inv)\n",
    "    \n",
    "    key_pts1_cylinder = ftn.transformHomo2Cylinder(key_pts1)\n",
    "    key_pts2_cylinder = ftn.transformHomo2Cylinder(key_pts2)\n",
    "    # b. find homogeneous coord in real space    \n",
    "    \n",
    "    theta = np.degrees(np.mean(key_pts2_cylinder[:,0] - key_pts1_cylinder[:,0]))\n",
    "    rot_angle_list.append(theta)\n",
    "\n",
    "print(np.sum(np.float32(rot_angle_list)))\n",
    "rot_angle_list.insert(0,0)\n",
    "\n",
    "rot_angle_list = 360/np.sum(rot_angle_list)*np.float32(rot_angle_list)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. OMNIDIRECTIONAL IMAGE RESTORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_cylinder = []\n",
    "factor = 4\n",
    "width = factor*470\n",
    "height = factor*110\n",
    "angle = 0\n",
    "# generate mask\n",
    "mask = 255 * np.uint8(np.ones((640, 640)))\n",
    "mask = ftn.cylindricalWarp(mask, K)\n",
    "mask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(mask, 254, 255, cv.THRESH_BINARY)\n",
    "min_idx_width, max_idx_width = ftn.findImgWidthDim(mask)\n",
    "mask = mask[:, min_idx_width:max_idx_width+1]\n",
    "mask = cv.resize(mask, (factor*110, height))\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "\n",
    "\n",
    "\n",
    "#combined image\n",
    "image_combined = np.uint8(np.zeros((height, width, 3)))\n",
    "\n",
    "# omnidirectional image restoration\n",
    "for i in range(21):\n",
    "    \n",
    "    # one omni. image\n",
    "    img_cyl = ftn.cylindricalWarp(colors_left_list[i], K)\n",
    "    img_cyl = img_cyl[:, :,0:3]\n",
    "    img_cyl = img_cyl[:, min_idx_width:max_idx_width+1]\n",
    "    img_cyl= cv.resize(img_cyl, (factor*110, height))\n",
    "    \n",
    "    # pixel movement\n",
    "    angle = angle + rot_angle_list[i]\n",
    "    angle_move = round(factor*angle)\n",
    "    \n",
    "    # restoration\n",
    "    roi = image_combined[:, width-angle_move-factor*110:width-angle_move]\n",
    "    \n",
    "    img_cyl_bg = cv.bitwise_and(roi, roi, mask=mask_inv)\n",
    "    img_cyl_fg = cv.bitwise_and(img_cyl, img_cyl, mask=mask)\n",
    "    dst = cv.add(img_cyl_bg, img_cyl_fg)\n",
    "    \n",
    "    image_combined[:, width-factor*110-angle_move:width-angle_move] = dst\n",
    "\n",
    "image_combined = image_combined[:, 55*factor:width-55*factor]\n",
    "_, w, _ = image_combined.shape\n",
    "dst =  copy.deepcopy(image_combined[:,0:round(w/2)])\n",
    "image_combined[:,0:round(w/2)] = image_combined[:,round(w/2):]\n",
    "image_combined[:,round(w/2):] = dst\n",
    "cv.imwrite('./combined.png', image_combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. OMNIDIRECTIONAL IMAGE RESTORATION\n",
    "6. OMNIDIRECTIONAL DISTANCE RESTORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /io/opencv/modules/core/src/arithm.cpp:672: error: (-5:Bad argument) When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-57dc07752a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdisp_cyl_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mdisp_cyl_fg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_cyl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp_cyl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_cyl_bg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp_cyl_fg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mdisp_combined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mangle_move\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mangle_move\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/core/src/arithm.cpp:672: error: (-5:Bad argument) When the input arrays in add/subtract/multiply/divide functions have different types, the output array type must be explicitly specified in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "factor = 4\n",
    "width = factor*470\n",
    "height = factor*110\n",
    "angle = 0\n",
    "disp_combined = np.uint8(np.zeros((height, width)))\n",
    "\n",
    "\n",
    "for i in range(21):\n",
    "\n",
    "    imgL = grays_left_list[i]\n",
    "    h,w = imgL.shape\n",
    "    imgR = grays_right_list[i]\n",
    "    imgR = cv.resize(imgR,(w,h))\n",
    "    \n",
    "    window_size = 3\n",
    "    stereo = cv.StereoSGBM_create(minDisparity=0,numDisparities = 256,\n",
    "                                  blockSize = 21,\n",
    "                                  P1= 8*3*window_size **2,\n",
    "                                  P2= 32*3*window_size **2,\n",
    "                                  disp12MaxDiff = 3,\n",
    "                                  uniquenessRatio = 15,\n",
    "                                  speckleWindowSize=0,\n",
    "                                  speckleRange=2,\n",
    "                                  preFilterCap=63,\n",
    "                                  mode=cv.STEREO_SGBM_MODE_SGBM_3WAY)\n",
    "    \n",
    "    disparity_SGBM = stereo.compute(imgL, imgR)\n",
    "\n",
    "    # Normalize the values to a range from 0..255 for a grayscale image\n",
    "    disparity_SGBM = cv.normalize(disparity_SGBM, disparity_SGBM, alpha=255,\n",
    "                                beta=0, norm_type=cv.NORM_MINMAX)\n",
    "    disparity_SGBM = np.uint8(disparity_SGBM)\n",
    "    \n",
    "    disp_cyl = ftn.cylindricalWarp_disp(disparity_SGBM, K)\n",
    "    #disp_cyl = disp_cyl[:, :,0:3]\n",
    "    disp_cyl = disp_cyl[:, min_idx_width:max_idx_width+1]\n",
    "    disp_cyl= cv.resize(disp_cyl, (factor*110, height))\n",
    "    \n",
    "    # pixel movement\n",
    "    angle = angle + rot_angle_list[i]\n",
    "    angle_move = round(factor*angle)\n",
    "    \n",
    "    # restoration\n",
    "    roi = disp_combined[:, width-angle_move-factor*110:width-angle_move]\n",
    "    \n",
    "    disp_cyl_bg = cv.bitwise_and(roi, roi, mask=mask_inv)\n",
    "    disp_cyl_fg = cv.bitwise_and(disp_cyl, disp_cyl, mask=mask)\n",
    "    dst = cv.add(disp_cyl_bg, disp_cyl_fg)\n",
    "    disp_combined[:, width-factor*110-angle_move:width-angle_move] = dst\n",
    "\n",
    "disp_combined = disp_combined[:, 55*factor:width-55*factor]\n",
    "_, w = disp_combined.shape\n",
    "dst =  copy.deepcopy(disp_combined[:,0:round(w/2)])\n",
    "disp_combined[:,0:round(w/2)] = disp_combined[:,round(w/2):]\n",
    "disp_combined[:,round(w/2):] = dst\n",
    "cv.imwrite('./disp_combined.png', disp_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. OMNIDIRECTIONAL DISTANCE RESTORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
