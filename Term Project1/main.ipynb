{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libararies\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as copy\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATCH KEYPOINTS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchKeyPoints(keyPoints1, keyPoints2, descriptors1, descriptors2):\n",
    "    \n",
    "    matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)\n",
    "    \n",
    "    descriptors1 = np.float32(descriptors1)\n",
    "    descriptors2 = np.float32(descriptors2)\n",
    "    \n",
    "    raw_matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    \n",
    "    matches = []\n",
    "    for m in raw_matches:\n",
    "        if len(m) == 2 and m[0].distance < m[1].distance * 0.75:\n",
    "            matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "    \n",
    "    if len(matches) > 4:\n",
    "        \n",
    "        keyPoints1 = np.float32([keyPoints1[i] for (_, i) in matches])\n",
    "        keyPoints2 = np.float32([keyPoints2[i] for (i, _) in matches])\n",
    "        \n",
    "        H, status = cv.findHomography(keyPoints1, keyPoints2, cv.RANSAC, 4.0)\n",
    "        \n",
    "        print('%d/%d inliers/matched' % (np.sum(status), len(status)))\n",
    "            \n",
    "    else:\n",
    "        H, status = None, None\n",
    "        print('%d matches found, not enough for homography estimation' % len(matches))\n",
    "    \n",
    "    return matches, H, status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIDTH DIMENSION FINDING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findImgWidthDim(Img):\n",
    "    min_idx = 10000\n",
    "    max_idx = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    _, width, _ = Img.shape\n",
    "\n",
    "    for idx in range(width):\n",
    "        if Img[150, idx, 0] == 0 and Img[150, idx, 1] == 0 and Img[150, idx, 2] == 0:\n",
    "            min_idx = idx\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    for idx in range(width):\n",
    "        if Img[150, width - idx - 1, 0] == 0 and Img[150, width - idx - 1, 1] == 0 and Img[150, width - idx - 1, 2] == 0:\n",
    "            max_idx = width - idx - 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return min_idx, max_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. IMPORT AND VISUALIZE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall color and gray images and mask\n",
    "color_ref = cv.imread('./PlanarImages/reference/Ref.jpg')\n",
    "gray_ref = cv.cvtColor(color_ref, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "path_colors = './PlanarImages/image/'\n",
    "path_masks = './PlanarImages/mask/'\n",
    "colors = []\n",
    "grays = []\n",
    "masks = []\n",
    "\n",
    "for root, directions, files in os.walk(path_colors):\n",
    "    \n",
    "    for file in files:\n",
    "        if '.jpg' in file:\n",
    "            \n",
    "            img_input = cv.imread(os.path.join(root, file))\n",
    "            gray_input = cv.cvtColor(img_input, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "            colors.append(img_input)\n",
    "            grays.append(gray_input)\n",
    "\n",
    "for root, directions, files in os.walk(path_masks):\n",
    "    \n",
    "    for file in files:\n",
    "        if '.png' in file:\n",
    "            \n",
    "            mask = cv.imread(os.path.join(root, file))\n",
    "            masks.append(mask)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. EXTRACT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature detector\n",
    "detector = cv.BRISK_create()\n",
    "key_pts_ref, descriptors_ref = detector.detectAndCompute(gray_ref, None)\n",
    "key_pts_ref = np.float32([key_pt.pt for key_pt in key_pts_ref])\n",
    "\n",
    "    # referenece image with buffer\n",
    "buffer = 300\n",
    "height_ref, width_ref, channel_ref = color_ref.shape\n",
    "color_ref_buffer = np.zeros((height_ref + 2*buffer, width_ref + 2*buffer, channel_ref), dtype=np.uint8)\n",
    "color_ref_buffer[0:height_ref, buffer-1:width_ref + buffer-1] = color_ref\n",
    "\n",
    "gray_ref_buffer = cv.cvtColor(color_ref_buffer, cv.COLOR_BGR2GRAY)\n",
    "key_pts_ref_buffer, descriptors_ref_buffer = detector.detectAndCompute(gray_ref_buffer, None)\n",
    "key_pts_ref_buffer = np.float32([key_pt.pt for key_pt in key_pts_ref_buffer])\n",
    "\n",
    "\n",
    "key_pts = []\n",
    "descriptors = []\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    key_pt, descriptor = detector.detectAndCompute(grays[i], None)\n",
    "    key_pt = np.float32([k_pt.pt for k_pt in key_pt])\n",
    "    key_pts.append(key_pt)\n",
    "    descriptors.append(descriptor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. MATCHING w/ RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 298, max: 1208\n",
      "4668/4841 inliers/matched\n",
      "2571/2727 inliers/matched\n",
      "2369/2709 inliers/matched\n",
      "2685/2839 inliers/matched\n"
     ]
    }
   ],
   "source": [
    "height_ref_buffer, width_ref_buffer, _ = color_ref_buffer.shape\n",
    "\n",
    "img_combined = color_ref_buffer.copy()\n",
    "min_idx, max_idx = findImgWidthDim(img_combined)\n",
    "print('min: %d, max: %d' % (min_idx, max_idx))\n",
    "for i in range(4):\n",
    "    key_pts_image = key_pts[i].copy()\n",
    "    descriptors_image = descriptors[i].copy()\n",
    "    matches, H, status = matchKeyPoints(key_pts_ref_buffer, key_pts_image, descriptors_ref_buffer, descriptors_image)\n",
    "    H_inv = np.linalg.inv(H)\n",
    "    H_inv = H_inv / H_inv[2,2]\n",
    "    result = cv.warpPerspective(colors[i], H_inv, \n",
    "                                (width_ref_buffer, height_ref_buffer))\n",
    "    result[0:img_combined.shape[0], min_idx:max_idx] = img_combined[0:img_combined.shape[0], min_idx:max_idx]\n",
    "    img_combined = result.copy()\n",
    "    min_idx, max_idx = findImgWidthDim(img_combined)\n",
    "\n",
    "\n",
    "\n",
    "cv.imshow('result', result)\n",
    "cv.waitKey(10000)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
