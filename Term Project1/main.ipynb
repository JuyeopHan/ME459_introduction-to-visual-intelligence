{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libararies\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as copy\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATCH KEYPOINTS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchKeyPoints(keyPoints1, keyPoints2, descriptors1, descriptors2):\n",
    "    \n",
    "    matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)\n",
    "    \n",
    "    descriptors1 = np.float32(descriptors1)\n",
    "    descriptors2 = np.float32(descriptors2)\n",
    "    \n",
    "    raw_matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    \n",
    "    matches = []\n",
    "    for m in raw_matches:\n",
    "        if len(m) == 2 and m[0].distance < m[1].distance * 0.75:\n",
    "            matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "    \n",
    "    if len(matches) > 4:\n",
    "        \n",
    "        keyPoints1 = np.float32([keyPoints1[i] for (_, i) in matches])\n",
    "        keyPoints2 = np.float32([keyPoints2[i] for (i, _) in matches])\n",
    "        \n",
    "        H, status = cv.findHomography(keyPoints1, keyPoints2, cv.RANSAC, 4.0)\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        H, status = None, None\n",
    "    \n",
    "    return matches, H, status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIDTH AND HEIGHT DIMENSION FINDING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findImgWidthDim(Img):\n",
    "    min_idx_width = 10000\n",
    "    max_idx_width = 0\n",
    "    min_idx_height = 10000\n",
    "    max_idx_height = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    height, width, _ = Img.shape\n",
    "\n",
    "    threshold = 120\n",
    "\n",
    "    for idx in range(width):\n",
    "        if Img[350, idx, 0] + Img[350, idx, 1] + Img[350, idx, 2] < threshold:\n",
    "            min_idx_width = idx + 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    for idx in range(width):\n",
    "        if Img[350, width - idx - 1, 0] + Img[350, width - idx - 1, 1] + Img[350, width - idx - 1, 2] < threshold:\n",
    "            max_idx_width = width - idx - 2\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    for idx in range(height):\n",
    "        if Img[idx, 350, 0] + Img[idx, 350, 1] + Img[idx, 350, 2] < threshold:\n",
    "            min_idx_height = idx + 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    for idx in range(height):\n",
    "        if Img[height - idx - 1, 350, 0] + Img[height - idx - 1, 350, 1] + Img[height - idx - 1, 350, 2] < threshold:\n",
    "            max_idx_height = width - idx - 2\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print('at width, min: %d, max: %d' % (min_idx_width, max_idx_width))\n",
    "    print('at height, min: %d, max: %d' % (min_idx_height, max_idx_height))\n",
    "    return min_idx_width, max_idx_width, min_idx_height, max_idx_height "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. IMPORT AND VISUALIZE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall color and gray images and mask\n",
    "color_ref = cv.imread('./PlanarImages/reference/Ref.jpg')\n",
    "gray_ref = cv.cvtColor(color_ref, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "path_colors = './PlanarImages/image/'\n",
    "path_masks = './PlanarImages/mask/'\n",
    "colors = []\n",
    "grays = []\n",
    "masks = []\n",
    "\n",
    "for root, directions, files in os.walk(path_colors):\n",
    "    \n",
    "    for file in files:\n",
    "        if '.jpg' in file:\n",
    "            \n",
    "            img_input = cv.imread(os.path.join(root, file))\n",
    "            gray_input = cv.cvtColor(img_input, cv.COLOR_BGR2GRAY)\n",
    "            \n",
    "            colors.append(img_input)\n",
    "            grays.append(gray_input)\n",
    "\n",
    "for root, directions, files in os.walk(path_masks):\n",
    "    \n",
    "    for file in files:\n",
    "        if '.png' in file:\n",
    "            \n",
    "            mask = cv.imread(os.path.join(root, file))\n",
    "            masks.append(mask)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. EXTRACT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature detector\n",
    "detector = cv.BRISK_create()\n",
    "key_pts_ref, descriptors_ref = detector.detectAndCompute(gray_ref, None)\n",
    "key_pts_ref = np.float32([key_pt.pt for key_pt in key_pts_ref])\n",
    "\n",
    "    # referenece image with buffer\n",
    "buffer = 200\n",
    "height_ref, width_ref, channel_ref = color_ref.shape\n",
    "color_ref_buffer = np.zeros((height_ref + 2*buffer, width_ref + 2*buffer, channel_ref), dtype=np.uint8)\n",
    "color_ref_buffer[buffer-1:height_ref + buffer-1, buffer-1:width_ref + buffer-1] = color_ref\n",
    "\n",
    "gray_ref_buffer = cv.cvtColor(color_ref_buffer, cv.COLOR_BGR2GRAY)\n",
    "key_pts_ref_buffer, descriptors_ref_buffer = detector.detectAndCompute(gray_ref_buffer, None)\n",
    "key_pts_ref_buffer = np.float32([key_pt.pt for key_pt in key_pts_ref_buffer])\n",
    "\n",
    "\n",
    "key_pts = []\n",
    "descriptors = []\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    key_pt, descriptor = detector.detectAndCompute(grays[i], None)\n",
    "    key_pt = np.float32([k_pt.pt for k_pt in key_pt])\n",
    "    key_pts.append(key_pt)\n",
    "    descriptors.append(descriptor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. MATCHING w/ RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at width, min: 201, max: 1105\n",
      "at height, min: 208, max: 1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juyeop/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  \n",
      "/home/juyeop/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "/home/juyeop/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "/home/juyeop/.local/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at width, min: 102, max: 1104\n",
      "at height, min: 200, max: 1105\n",
      "at width, min: 6, max: 1102\n",
      "at height, min: 200, max: 1105\n",
      "at width, min: 6, max: 1286\n",
      "at height, min: 200, max: 1105\n",
      "at width, min: 6, max: 1285\n",
      "at height, min: 199, max: 1105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height_ref_buffer, width_ref_buffer, _ = color_ref_buffer.shape\n",
    "\n",
    "img_combined = color_ref_buffer.copy()\n",
    "min_idx_width, max_idx_width, min_idx_height, max_idx_height = findImgWidthDim(img_combined)\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    matches, H, status = matchKeyPoints(key_pts[i], key_pts_ref_buffer, descriptors[i], descriptors_ref_buffer)\n",
    "    result = cv.warpPerspective(colors[i], H, (width_ref_buffer, height_ref_buffer))\n",
    "    result[min_idx_height:max_idx_height, min_idx_width:max_idx_width] = img_combined[min_idx_height:max_idx_height, min_idx_width:max_idx_width]\n",
    "    img_combined = result.copy()\n",
    "    min_idx_width, max_idx_width, min_idx_height, max_idx_height = findImgWidthDim(img_combined)\n",
    "\n",
    "\n",
    "\n",
    "cv.imwrite('./Result.png', img_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_set = []\n",
    "f = open('./TP1_homography.txt','w')\n",
    "for i in range(4):\n",
    "    key_pts_image = key_pts[i].copy()\n",
    "    descriptors_image = descriptors[i].copy()\n",
    "    matches, H, status = matchKeyPoints(key_pts_image, key_pts_ref, descriptors_image, descriptors_ref)\n",
    "    H = np.reshape(H, (1, 9))\n",
    "    \n",
    "    for j in range(9):\n",
    "        f.write('%f '% H[0,j])\n",
    "    f.write('\\n')\n",
    "    \n",
    "    H_set.append(H)\n",
    "\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
